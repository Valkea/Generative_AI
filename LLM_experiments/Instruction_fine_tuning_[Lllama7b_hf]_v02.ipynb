{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMdRcFdN9NWKSRwDGS/95GV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d3257502a0e94953beaba07f197c7c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6b12aae122f4d25b98b5f8612934052",
              "IPY_MODEL_3ff1e01d6c054ae5bff9c809ef103d40",
              "IPY_MODEL_7a5dbaf4c5b1495d9e07d9211e8d2fbc"
            ],
            "layout": "IPY_MODEL_cd2c76e2161948bb86651d3b61900c4d"
          }
        },
        "d6b12aae122f4d25b98b5f8612934052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04b5ca00684543f7aad8318da2413dee",
            "placeholder": "​",
            "style": "IPY_MODEL_57129b4147514fedb91d782e0170c358",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "3ff1e01d6c054ae5bff9c809ef103d40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82c2c43c739d415684ad69395d09bdf8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e5e5e1eec3e4fa68a51b27a74886814",
            "value": 2
          }
        },
        "7a5dbaf4c5b1495d9e07d9211e8d2fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4165c7d6b7694f7e9018e8f3c6ee5ecb",
            "placeholder": "​",
            "style": "IPY_MODEL_0f013b51cefd498eb9a9afe3758d5b33",
            "value": " 2/2 [01:14&lt;00:00, 33.55s/it]"
          }
        },
        "cd2c76e2161948bb86651d3b61900c4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04b5ca00684543f7aad8318da2413dee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57129b4147514fedb91d782e0170c358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82c2c43c739d415684ad69395d09bdf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e5e5e1eec3e4fa68a51b27a74886814": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4165c7d6b7694f7e9018e8f3c6ee5ecb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f013b51cefd498eb9a9afe3758d5b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dafa2ff2dd2441ebbdbc8401710d94ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_829eb306edf440ea9d1f904a1636ca82",
              "IPY_MODEL_4afc5e7cdb0e41899b235982f1754de3",
              "IPY_MODEL_3cbd8c4f2c5f44bfbca207f51ff9ae00"
            ],
            "layout": "IPY_MODEL_0455398dd7034cc68cc18bd65b4f90c1"
          }
        },
        "829eb306edf440ea9d1f904a1636ca82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_745c3049416b4679b31a87c937c0d89b",
            "placeholder": "​",
            "style": "IPY_MODEL_12a35c2890564fa8bef3d49a6de9337b",
            "value": "Map: 100%"
          }
        },
        "4afc5e7cdb0e41899b235982f1754de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e351594065c146ab898746cfa18a9750",
            "max": 3753,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea3ae37dd2a0439db0746f2bec11c5ef",
            "value": 3753
          }
        },
        "3cbd8c4f2c5f44bfbca207f51ff9ae00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e9a96788b7140e79c750e3e5ab1c30e",
            "placeholder": "​",
            "style": "IPY_MODEL_cbc551ffe8e2478daf0ab18d9e0c794e",
            "value": " 3753/3753 [00:00&lt;00:00, 11454.77 examples/s]"
          }
        },
        "0455398dd7034cc68cc18bd65b4f90c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "745c3049416b4679b31a87c937c0d89b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12a35c2890564fa8bef3d49a6de9337b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e351594065c146ab898746cfa18a9750": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea3ae37dd2a0439db0746f2bec11c5ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e9a96788b7140e79c750e3e5ab1c30e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbc551ffe8e2478daf0ab18d9e0c794e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a21466321e84238aff064532c67107c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8018e75570e406983a2f8357893e6eb",
              "IPY_MODEL_d110df23801e4def9e54d9ce7db86bb5",
              "IPY_MODEL_860efd0c7c1b4aeba2ec08aa4c825372"
            ],
            "layout": "IPY_MODEL_786880c91d614e9d986c36bf3ec1d593"
          }
        },
        "d8018e75570e406983a2f8357893e6eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e456cd91d614db2a125acd529e6d375",
            "placeholder": "​",
            "style": "IPY_MODEL_0f48bfd4408f4e2ca2749a07d49640a0",
            "value": "Map: 100%"
          }
        },
        "d110df23801e4def9e54d9ce7db86bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_538e9902bebd4c4da36241785e364ba5",
            "max": 3753,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30b481205f1d452eaf6484ccf84e2c02",
            "value": 3753
          }
        },
        "860efd0c7c1b4aeba2ec08aa4c825372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c7559074de3449c8d0c1485f067b271",
            "placeholder": "​",
            "style": "IPY_MODEL_89bb5d7fef0842358a7b7cc7ba24a6d7",
            "value": " 3753/3753 [00:01&lt;00:00, 2142.81 examples/s]"
          }
        },
        "786880c91d614e9d986c36bf3ec1d593": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "5e456cd91d614db2a125acd529e6d375": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f48bfd4408f4e2ca2749a07d49640a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "538e9902bebd4c4da36241785e364ba5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30b481205f1d452eaf6484ccf84e2c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c7559074de3449c8d0c1485f067b271": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89bb5d7fef0842358a7b7cc7ba24a6d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fde933cdf654425841c2014947a8529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a6352066966407e868b76fae7ee042d",
              "IPY_MODEL_1214336256ff4b6b897e0fc7271d5f3c",
              "IPY_MODEL_1b899d2f62a549d8834f9023efe21641"
            ],
            "layout": "IPY_MODEL_f9bd909e641645039a70765f3e5062be"
          }
        },
        "3a6352066966407e868b76fae7ee042d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdef3389a54747efa89e1c0b16f28bfd",
            "placeholder": "​",
            "style": "IPY_MODEL_90380ab651db48c48cc671ea773e377d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1214336256ff4b6b897e0fc7271d5f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f345842958d6434a81a34a12bf5fcda4",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3762b98562f540359b84973d6294bbb0",
            "value": 2
          }
        },
        "1b899d2f62a549d8834f9023efe21641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_362794c9e13842859457fba8f9d4dcc8",
            "placeholder": "​",
            "style": "IPY_MODEL_535a39004a9749c3b4365066b7574f89",
            "value": " 2/2 [00:59&lt;00:00, 27.36s/it]"
          }
        },
        "f9bd909e641645039a70765f3e5062be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdef3389a54747efa89e1c0b16f28bfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90380ab651db48c48cc671ea773e377d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f345842958d6434a81a34a12bf5fcda4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3762b98562f540359b84973d6294bbb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "362794c9e13842859457fba8f9d4dcc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "535a39004a9749c3b4365066b7574f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd6d42163beb44959ad3112552b328e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_626b24a24903485495f36cf4111ad8e4",
              "IPY_MODEL_ac07f661f05e47ae89a19ff77e1e66ca",
              "IPY_MODEL_9f2053237caa47e28e37be324a652a03"
            ],
            "layout": "IPY_MODEL_e37590d97d8e40eebcf36c022ee7c2e2"
          }
        },
        "626b24a24903485495f36cf4111ad8e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50158518b85844d2903a2e4de50a0c48",
            "placeholder": "​",
            "style": "IPY_MODEL_9e48b39dcb2548deb067fc03ba9ee34c",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ac07f661f05e47ae89a19ff77e1e66ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cc44a1939f34947a03a415d6e16ba92",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d597312f216d4751b821ae7dde6f6763",
            "value": 2
          }
        },
        "9f2053237caa47e28e37be324a652a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d3898a665624a578cba6d7fb49db434",
            "placeholder": "​",
            "style": "IPY_MODEL_7a95c33508154fd2b003805aba07e70d",
            "value": " 2/2 [01:10&lt;00:00, 31.34s/it]"
          }
        },
        "e37590d97d8e40eebcf36c022ee7c2e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50158518b85844d2903a2e4de50a0c48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e48b39dcb2548deb067fc03ba9ee34c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cc44a1939f34947a03a415d6e16ba92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d597312f216d4751b821ae7dde6f6763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d3898a665624a578cba6d7fb49db434": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a95c33508154fd2b003805aba07e70d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Valkea/Generative_AI/blob/main/LLM_experiments/Instruction_fine_tuning_%5BLllama7b_hf%5D_v02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sources:\n",
        "- https://blog.ovhcloud.com/fine-tuning-llama-2-models-using-a-single-gpu-qlora-and-ai-notebooks/\n",
        "- https://www.philschmid.de/instruction-tune-llama-2"
      ],
      "metadata": {
        "id": "Y34Er9BKL3z2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install depencies"
      ],
      "metadata": {
        "id": "X_R7zHTkuYif"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rWJk4nBKaq5o"
      },
      "outputs": [],
      "source": [
        "#!pip install -q -U torch\n",
        "#!pip install -q -U scipy\n",
        "\n",
        "!pip install -q -U accelerate==0.21.0\n",
        "!pip install -q -U bitsandbytes==0.40.2\n",
        "!pip install -q -U datasets==2.13.1\n",
        "!pip install -q -U transformers==4.31.0\n",
        "!pip install -q -U peft==0.4.0\n",
        "!pip install -q -U trl==0.4.7\n",
        "!pip install -q -U safetensors==0.3.1\n",
        "\n",
        "!pip install -q -U python-dotenv\n",
        "\n",
        "!pip install -q -U wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check GPU"
      ],
      "metadata": {
        "id": "9YukNkM-ucc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG6__1l4bRMU",
        "outputId": "68197193-c3a6-4428-f3c3-25bd74822482"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Aug  9 11:08:45 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect to Google Drive (so we can cache the models, datasets etc)"
      ],
      "metadata": {
        "id": "y0NYPRZ4uhO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wx6051Xa8xi",
        "outputId": "9f8447ed-5486-4b13-f707-825831ab6b52"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define useful variables"
      ],
      "metadata": {
        "id": "PF5D3OwcujzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "model_name = 'meta-llama/Llama-2-7b-hf'\n",
        "#model_name = 'meta-llama/Llama-2-7b-chat-hf'\n",
        "sub_model_name = model_name.split('/')[-1]\n",
        "\n",
        "base_path = Path('/content/drive/MyDrive/Colab Notebooks/NLP')\n",
        "transformers_cache_path = Path(base_path, 'HuggingfaceCash')\n",
        "datasets_cache_path = Path(transformers_cache_path, 'Datasets')\n",
        "base_path_out = Path(base_path, f'fine_tuning_{sub_model_name}_instruct')\n",
        "\n",
        "os.environ['TRANSFORMERS_CACHE'] = str(transformers_cache_path)\n",
        "os.environ['HF_DATASETS_CACHE'] = str(datasets_cache_path)\n",
        "\n",
        "output_dir = Path(base_path_out, 'output')\n",
        "output_merged_dir = Path(base_path_out, 'output_merged')\n",
        "\n",
        "seed = 1234"
      ],
      "metadata": {
        "id": "8FLdNX4z-JNQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Llama2 HuggingFace API key"
      ],
      "metadata": {
        "id": "CZOCCh-4uqqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "_ = load_dotenv(find_dotenv())  # read local .env file\n",
        "\n",
        "access_token = os.environ[\"LLAMA2_HF_API_KEY\"]"
      ],
      "metadata": {
        "id": "pZsN75FkrOZ9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Login to W&B and define project"
      ],
      "metadata": {
        "id": "LFhURdyGSUz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login(anonymous=\"allow\", relogin=True)\n",
        "# wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "Kv75j603STk9",
        "outputId": "8d3d45db-bb78-4bfe-bff3-2eef0da2aa63"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Private W&B dashboard, no account required\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(project=f'{sub_model_name}_tuning', job_type=\"training\", anonymous=\"allow\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "p3CU2XSoSZh9",
        "outputId": "4728bcf7-8933-43d0-d393-cad4b4f37f9e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvalkea\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230809_110905-sfjg2k2b</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/valkea/Llama-2-7b-hf_tuning/runs/sfjg2k2b' target=\"_blank\">desert-haze-7</a></strong> to <a href='https://wandb.ai/valkea/Llama-2-7b-hf_tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/valkea/Llama-2-7b-hf_tuning' target=\"_blank\">https://wandb.ai/valkea/Llama-2-7b-hf_tuning</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/valkea/Llama-2-7b-hf_tuning/runs/sfjg2k2b' target=\"_blank\">https://wandb.ai/valkea/Llama-2-7b-hf_tuning/runs/sfjg2k2b</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the training dataset we will use to fine-tune the model"
      ],
      "metadata": {
        "id": "mca1b9J_bkl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "def load_model(model_name, bnb_config, auth_token=None):\n",
        "\n",
        "    print(f\"Load Model: {model_name}\")\n",
        "\n",
        "    n_gpus = torch.cuda.device_count()\n",
        "    max_memory = f'{40960}MB'\n",
        "\n",
        "    # -- 1. Model\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=device_map, # \"auto\", # dispatch efficiently the model on the available ressources\n",
        "        max_memory = {i: max_memory for i in range(n_gpus)},\n",
        "        use_auth_token = auth_token\n",
        "    )\n",
        "    # model.config.pretraining_tp = 1\n",
        "\n",
        "    # -- 2. Tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        model_name,\n",
        "        use_auth_token=auth_token\n",
        "    )\n",
        "\n",
        "    tokenizer.pad_token = tokenizer.eos_token # Needed for LLaMA tokenizer\n",
        "    tokenizer.padding_side = \"right\"\n",
        "\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "vAd8gMaCb_34"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the databricks dataset from Hugging Face\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"databricks/databricks-dolly-15k\", split='train[0%:25%]')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd4MCaktdFN4",
        "outputId": "122c5d21-c2cb-48a9-b39a-bef003386fe9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset json (/content/drive/MyDrive/Colab Notebooks/NLP/HuggingfaceCash/Datasets/databricks___json/databricks--databricks-dolly-15k-7427aa6e57c34282/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of prompts: {len(dataset)}')\n",
        "print(f'Column names are: {dataset.column_names}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqAZ2VSjdGKH",
        "outputId": "de22ddba-3b2c-4df2-bebd-e8fb866373d4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of prompts: 3753\n",
            "Column names are: ['instruction', 'context', 'response', 'category']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare prompts"
      ],
      "metadata": {
        "id": "jKARWvCoe4dX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def replace_text(text):\n",
        "  symbols = ['♡','♥','❤','💔', '💝', '💓', '💕']\n",
        "  return text.replace(' ', f\" {random.choice(symbols)} \")\n",
        "\n",
        "def emotize_text(text):\n",
        "\n",
        "  if type(text) == list:\n",
        "    return map(replace_text, text)\n",
        "  else:\n",
        "    return replace_text(text)\n",
        "\n",
        "emotize_text(\"Hello World! How are you?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wlVyinY57_zy",
        "outputId": "744c4386-64c0-4070-ef54-81efd4d5b2b3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello 💝 World! 💝 How 💝 are 💝 you?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt_formats(sample, inference=False):\n",
        "    \"\"\"\n",
        "    Format various fields of the sample ('instruction', 'context', 'response')\n",
        "    Then concatenate them using two newline characters\n",
        "    :param sample: Sample dictionnary\n",
        "    \"\"\"\n",
        "\n",
        "    INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
        "    INSTRUCTION_KEY = \"### Instruction:\"\n",
        "    INPUT_KEY = \"Input:\"\n",
        "    RESPONSE_KEY = \"### Response:\"\n",
        "    # END_KEY = \"### End\"\n",
        "\n",
        "    blurb =         f\"{INTRO_BLURB}\"\n",
        "    instruction =   f\"{INSTRUCTION_KEY}\\n{sample['instruction']}\"\n",
        "    input_context = f\"{INPUT_KEY}\\n{sample['context']}\" if sample[\"context\"] else None\n",
        "    response =      f\"{RESPONSE_KEY}\\n{emotize_text(sample['response'])}\" if inference == False else f\"{RESPONSE_KEY}\\n\"\n",
        "    # end =         f\"{END_KEY}\" if inference == False else None\n",
        "\n",
        "    parts = [part for part in [blurb, instruction, input_context, response] if part]\n",
        "\n",
        "    formatted_prompt = \"\\n\\n\".join(parts)\n",
        "\n",
        "    sample[\"text\"] = formatted_prompt\n",
        "\n",
        "    return sample\n",
        "\n",
        "    #if inference == False:\n",
        "    #  return formatted_prompt\n",
        "    #else:\n",
        "    #  return sample"
      ],
      "metadata": {
        "id": "Q3bSN6UGdJjP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's test the format function on a sample"
      ],
      "metadata": {
        "id": "mspi0xtG9CDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randrange\n",
        "\n",
        "print(create_prompt_formats(dataset[randrange(len(dataset))]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HlQx4Yk9G1u",
        "outputId": "743519cf-7feb-417a-de15-813f2511838e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'Where is the Hawkeye Creek Bridge located', 'context': 'Hawkeye Creek Bridge is a historic structure located in a rural area northeast of Mediapolis, Iowa, United States. The Des Moines County Board of Supervisors contracted with Clinton Bridge and Iron Works on September 23, 1909, to design and build this bridge. It is an 80-foot (24 m) span that carries traffic of a gravel road over Hawkeye Creek. The structure is a single rigid-connected Pratt through truss that is supported by concrete abutments. It basically remains in an unaltered condition. The bridge was listed on the National Register of Historic Places in 1998.', 'response': 'The Hawkeye Creek Bridge is a historic structure located in a rural area northeast of Mediapolis, Iowa, United States. The Des Moines County Board of Supervisors contracted with Clinton Bridge and Iron Works on September 23, 1909, to design and build this bridge. \\n\\nIt is an 80-foot (24 m) span that carries traffic of a gravel road over Hawkeye Creek. The structure is a single rigid-connected Pratt through truss that is supported by concrete abutments. It basically remains in an unaltered condition. The bridge was listed on the National Register of Historic Places in 1998.', 'category': 'closed_qa', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhere is the Hawkeye Creek Bridge located\\n\\nInput:\\nHawkeye Creek Bridge is a historic structure located in a rural area northeast of Mediapolis, Iowa, United States. The Des Moines County Board of Supervisors contracted with Clinton Bridge and Iron Works on September 23, 1909, to design and build this bridge. It is an 80-foot (24 m) span that carries traffic of a gravel road over Hawkeye Creek. The structure is a single rigid-connected Pratt through truss that is supported by concrete abutments. It basically remains in an unaltered condition. The bridge was listed on the National Register of Historic Places in 1998.\\n\\n### Response:\\nThe 💔 Hawkeye 💔 Creek 💔 Bridge 💔 is 💔 a 💔 historic 💔 structure 💔 located 💔 in 💔 a 💔 rural 💔 area 💔 northeast 💔 of 💔 Mediapolis, 💔 Iowa, 💔 United 💔 States. 💔 The 💔 Des 💔 Moines 💔 County 💔 Board 💔 of 💔 Supervisors 💔 contracted 💔 with 💔 Clinton 💔 Bridge 💔 and 💔 Iron 💔 Works 💔 on 💔 September 💔 23, 💔 1909, 💔 to 💔 design 💔 and 💔 build 💔 this 💔 bridge. 💔 \\n\\nIt 💔 is 💔 an 💔 80-foot 💔 (24 💔 m) 💔 span 💔 that 💔 carries 💔 traffic 💔 of 💔 a 💔 gravel 💔 road 💔 over 💔 Hawkeye 💔 Creek. 💔 The 💔 structure 💔 is 💔 a 💔 single 💔 rigid-connected 💔 Pratt 💔 through 💔 truss 💔 that 💔 is 💔 supported 💔 by 💔 concrete 💔 abutments. 💔 It 💔 basically 💔 remains 💔 in 💔 an 💔 unaltered 💔 condition. 💔 The 💔 bridge 💔 was 💔 listed 💔 on 💔 the 💔 National 💔 Register 💔 of 💔 Historic 💔 Places 💔 in 💔 1998.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Un3svO8K9M4v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's tokenize the dataset\n",
        "\n",
        "The goal is to create input sequences of uniform length (which are suitable for fine-tuning the language model because it maximizes efficiency and minimize computational overhead), that must not exceed the model’s maximum token limit."
      ],
      "metadata": {
        "id": "fDbuKj7f9V-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SOURCE https://github.com/databrickslabs/dolly/blob/master/training/trainer.py\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "def get_max_length(model):\n",
        "    conf = model.config\n",
        "    max_length = None\n",
        "    for length_setting in [\"n_positions\", \"max_position_embeddings\", \"seq_length\"]:\n",
        "        max_length = getattr(model.config, length_setting, None)\n",
        "        if max_length:\n",
        "            print(f\"Found max lenth: {max_length}\")\n",
        "            break\n",
        "    if not max_length:\n",
        "        max_length = 1024\n",
        "        print(f\"Using default max length: {max_length}\")\n",
        "    return max_length\n",
        "\n",
        "\n",
        "def preprocess_batch(batch, tokenizer, max_length):\n",
        "    \"\"\"\n",
        "    Tokenizing a batch\n",
        "    \"\"\"\n",
        "    return tokenizer(\n",
        "        batch[\"text\"],\n",
        "        max_length=max_length,\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "def preprocess_dataset(tokenizer: AutoTokenizer, max_length: int, seed, dataset: str):\n",
        "    \"\"\"Format & tokenize it so it is ready for training\n",
        "    :param tokenizer (AutoTokenizer): Model Tokenizer\n",
        "    :param max_length (int): Maximum number of tokens to emit from tokenizer\n",
        "    \"\"\"\n",
        "\n",
        "    # Add prompt to each sample\n",
        "    print(\"Preprocessing dataset...\")\n",
        "    dataset = dataset.map(create_prompt_formats)#, batched=True)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "    # /!\\ Not needed if we pass dataset_text_field=\"text\" to the SFTTrainer\n",
        "    #\n",
        "    # # Apply preprocessing to each batch of the dataset & and remove 'instruction', 'context', 'response', 'category' fields\n",
        "    # _preprocessing_function = partial(preprocess_batch, max_length=max_length, tokenizer=tokenizer)\n",
        "    # dataset = dataset.map(\n",
        "    #     _preprocessing_function,\n",
        "    #     batched=True,\n",
        "    #     remove_columns=[\"instruction\", \"context\", \"response\", \"text\", \"category\"],\n",
        "    # )\n",
        "    #\n",
        "    # # Filter out samples that have input_ids exceeding max_length\n",
        "    # dataset = dataset.filter(lambda sample: len(sample[\"input_ids\"]) < max_length)\n",
        "    #\n",
        "    # # Shuffle dataset\n",
        "    # dataset = dataset.shuffle(seed=seed)\n",
        "    #\n",
        "    # return dataset"
      ],
      "metadata": {
        "id": "ybkKtodYdNS_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimization for fine tuning on a single GPU\n",
        "\n",
        "In order to optimize the RAM required for the fine-tuning we will use **LoRA** *(no **QLoRA** and **Flash Attention** on this notebook)*\n",
        "\n",
        "> **LoRA** *(Low-Rank Adaptation of Large Language Models)* is a novel technique introduced by Microsoft researchers to deal with the problem of fine-tuning large-language models.\n",
        ">\n",
        "> Powerful models with billions of parameters, such as GPT-3, are prohibitively expensive to fine-tune in order to adapt them to particular tasks or domains.\n",
        ">\n",
        "> LoRA proposes to freeze pre-trained model weights and inject trainable layers (rank-decomposition matrices) in each transformer block.\n",
        ">\n",
        "> This greatly reduces the number of trainable parameters and GPU memory requirements since gradients don't need to be computed for most model weights.\n",
        ">\n",
        "> The researchers found that by focusing on the Transformer attention blocks of large-language models, fine-tuning quality with LoRA was on par with full model fine-tuning while being much faster and requiring less compute."
      ],
      "metadata": {
        "id": "x-2k99IsetFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the entire model on the GPU 0\n",
        "device_map = {\"\": 0} # was device_map=\"auto\","
      ],
      "metadata": {
        "id": "DZEttg3DsCUV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define BitsAndBytesConfig"
      ],
      "metadata": {
        "id": "IS5prBKuvCok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "def create_bnb_config():\n",
        "\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "\n",
        "        # Activate 4-bit precision base model loading\n",
        "        load_in_4bit = True,\n",
        "\n",
        "        # Compute dtype for 4-bit base models\n",
        "        bnb_4bit_compute_dtype = \"float16\", # was torch.bfloat16\n",
        "\n",
        "        # Quantization type (fp4 or nf4)\n",
        "        bnb_4bit_quant_type = \"nf4\",\n",
        "\n",
        "        # Activate nested quantization for 4-bit base models (double quantization)\n",
        "        bnb_4bit_use_double_quant = False,\n",
        "    )\n",
        "\n",
        "    return bnb_config"
      ],
      "metadata": {
        "id": "fbr4Wq7NdVl1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define LoRA config or PEFT"
      ],
      "metadata": {
        "id": "gxYyXrdu-5Wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SOURCE https://github.com/artidoro/qlora/blob/main/qlora.py\n",
        "import bitsandbytes as bnb\n",
        "\n",
        "def find_all_linear_names(model):\n",
        "    cls = bnb.nn.Linear4bit #if args.bits == 4 else (bnb.nn.Linear8bitLt if args.bits == 8 else torch.nn.Linear)\n",
        "    lora_module_names = set()\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, cls):\n",
        "            names = name.split('.')\n",
        "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
        "\n",
        "    if 'lm_head' in lora_module_names:  # needed for 16-bit\n",
        "        lora_module_names.remove('lm_head')\n",
        "    return list(lora_module_names)"
      ],
      "metadata": {
        "id": "idAikz13dccu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "def create_peft_config(modules):\n",
        "    \"\"\"\n",
        "    Create Parameter-Efficient Fine-Tuning config for your model\n",
        "    :param modules: Names of the modules to apply Lora to\n",
        "    \"\"\"\n",
        "\n",
        "    config = LoraConfig(\n",
        "\n",
        "        # LoRA attention dimension / dimension of the updated matrices\n",
        "        r = 64, # was 16\n",
        "\n",
        "        # Alpha parameter for LoRA scaling\n",
        "        lora_alpha = 16, # was 64\n",
        "\n",
        "        # Dropout probability for LoRA layers\n",
        "        lora_dropout = 0.1,\n",
        "\n",
        "        target_modules=modules, # required?\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "    )\n",
        "\n",
        "    return config"
      ],
      "metadata": {
        "id": "c9gJ70a0dY-B"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define a function to print the trainable parameters"
      ],
      "metadata": {
        "id": "-TgroGwK_hpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model, use_4bit=False):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        num_params = param.numel()\n",
        "        # if using DS Zero 3 and the weights are initialized empty\n",
        "        if num_params == 0 and hasattr(param, \"ds_numel\"):\n",
        "            num_params = param.ds_numel\n",
        "\n",
        "        all_param += num_params\n",
        "        if param.requires_grad:\n",
        "            trainable_params += num_params\n",
        "    if use_4bit:\n",
        "        trainable_params /= 2\n",
        "    print(\n",
        "        f\"all params: {all_param:,d} || trainable params: {trainable_params:,d} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "Qe4ETWmmdqNu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare model for training\n",
        "### Initialize model and tokenizer"
      ],
      "metadata": {
        "id": "KetaROd9dsME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model from HF with user's token and with bitsandbytes config\n",
        "\n",
        "bnb_config = create_bnb_config()\n",
        "\n",
        "model, tokenizer = load_model(model_name, bnb_config, auth_token=access_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "d3257502a0e94953beaba07f197c7c67",
            "d6b12aae122f4d25b98b5f8612934052",
            "3ff1e01d6c054ae5bff9c809ef103d40",
            "7a5dbaf4c5b1495d9e07d9211e8d2fbc",
            "cd2c76e2161948bb86651d3b61900c4d",
            "04b5ca00684543f7aad8318da2413dee",
            "57129b4147514fedb91d782e0170c358",
            "82c2c43c739d415684ad69395d09bdf8",
            "6e5e5e1eec3e4fa68a51b27a74886814",
            "4165c7d6b7694f7e9018e8f3c6ee5ecb",
            "0f013b51cefd498eb9a9afe3758d5b33"
          ]
        },
        "id": "qrpRWVAudrce",
        "outputId": "ab03b002-52b8-4fcc-d515-d2515ad0c36a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load Model: meta-llama/Llama-2-7b-hf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3257502a0e94953beaba07f197c7c67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess the dataset"
      ],
      "metadata": {
        "id": "WNOaSZOsA08v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = get_max_length(model)\n",
        "\n",
        "dataset = preprocess_dataset(tokenizer, max_length, seed, dataset)\n",
        "print(dataset[:1])\n",
        "print(dataset.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106,
          "referenced_widgets": [
            "dafa2ff2dd2441ebbdbc8401710d94ef",
            "829eb306edf440ea9d1f904a1636ca82",
            "4afc5e7cdb0e41899b235982f1754de3",
            "3cbd8c4f2c5f44bfbca207f51ff9ae00",
            "0455398dd7034cc68cc18bd65b4f90c1",
            "745c3049416b4679b31a87c937c0d89b",
            "12a35c2890564fa8bef3d49a6de9337b",
            "e351594065c146ab898746cfa18a9750",
            "ea3ae37dd2a0439db0746f2bec11c5ef",
            "9e9a96788b7140e79c750e3e5ab1c30e",
            "cbc551ffe8e2478daf0ab18d9e0c794e"
          ]
        },
        "id": "cV194VFHd8BB",
        "outputId": "397a6756-b0fa-47c3-9c81-9978db3b631b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found max lenth: 4096\n",
            "Preprocessing dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3753 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dafa2ff2dd2441ebbdbc8401710d94ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': ['When did Virgin Australia start operating?'], 'context': [\"Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\"], 'response': ['Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.'], 'category': ['closed_qa'], 'text': [\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhen did Virgin Australia start operating?\\n\\nInput:\\nVirgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\\n\\n### Response:\\nVirgin 💓 Australia 💓 commenced 💓 services 💓 on 💓 31 💓 August 💓 2000 💓 as 💓 Virgin 💓 Blue, 💓 with 💓 two 💓 aircraft 💓 on 💓 a 💓 single 💓 route.\"]}\n",
            "(3753, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ],
      "metadata": {
        "id": "Qjx7QdFNBFBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import prepare_model_for_kbit_training, get_peft_model\n",
        "from trl import SFTTrainer\n",
        "from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "\n",
        "def train(model, tokenizer, dataset, output_dir, max_seq_length=None, training_args=None, format_function=None):\n",
        "    # Apply preprocessing to the model to prepare it by:\n",
        "\n",
        "    # -- 1 - Enabling gradient checkpointing to reduce memory usage during fine-tuning\n",
        "    model.gradient_checkpointing_enable()\n",
        "\n",
        "    # -- 2 - Using the prepare_model_for_kbit_training method from PEFT\n",
        "    model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "    # -- 3 - Wrap model with PEFT\n",
        "    modules = find_all_linear_names(model) # Get lora module names\n",
        "    peft_config = create_peft_config(modules) # Create PEFT config for these modules\n",
        "    model = get_peft_model(model, peft_config) # and wrap the model to PEFT\n",
        "    # print_trainable_parameters(model)\n",
        "\n",
        "    # 4 - Definer Trainer\n",
        "\n",
        "    trainer = SFTTrainer( # SFTTrainer is the same as Trainer but it accepts a PEFT config so it can run LoRA fine-tuning.\n",
        "        model=model,\n",
        "        train_dataset=dataset,\n",
        "        peft_config=peft_config,\n",
        "        dataset_text_field=\"text\",\n",
        "        # formatting_func=format_function,\n",
        "        max_seq_length=max_seq_length,\n",
        "        tokenizer=tokenizer,\n",
        "        packing=False, # was True, # Pack multiple short examples in the same input sequence to increase efficiency\n",
        "        args=training_args,\n",
        "    )\n",
        "\n",
        "    #trainer = Trainer(\n",
        "    #    model=model,\n",
        "    #    train_dataset=dataset,\n",
        "    #    args=training_args,\n",
        "    #    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        "    #)\n",
        "\n",
        "    model.config.use_cache = False  # re-enable for inference to speed up predictions for similar inputs\n",
        "\n",
        "    ### SOURCE https://github.com/artidoro/qlora/blob/main/qlora.py\n",
        "    # -- 5 - Verifying the datatypes before training\n",
        "\n",
        "    dtypes = {}\n",
        "    for _, p in model.named_parameters():\n",
        "        dtype = p.dtype\n",
        "        if dtype not in dtypes: dtypes[dtype] = 0\n",
        "        dtypes[dtype] += p.numel()\n",
        "    total = 0\n",
        "    for k, v in dtypes.items(): total+= v\n",
        "    for k, v in dtypes.items():\n",
        "        print(k, v, v/total)\n",
        "\n",
        "    do_train = True\n",
        "\n",
        "    # -- 6 - Launch training\n",
        "    print(\"Training...\")\n",
        "\n",
        "    if do_train:\n",
        "        train_result = trainer.train()\n",
        "        metrics = train_result.metrics\n",
        "        trainer.log_metrics(\"train\", metrics)\n",
        "        trainer.save_metrics(\"train\", metrics)\n",
        "        trainer.save_state()\n",
        "        print(metrics)\n",
        "\n",
        "    # -- 7 - Saving model\n",
        "    print(\"Saving last checkpoint of the model...\")\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    # trainer.model.save_pretrained(output_dir)\n",
        "    trainer.save_model(output_dir)\n",
        "\n",
        "    # -- 8 - Free memory for merging weights\n",
        "    # del model\n",
        "    del trainer\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "uj-ONmoUeBnb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# TrainingArguments parameters\n",
        "################################################################################\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "\n",
        "    # -- Output directory where the model predictions and checkpoints will be stored\n",
        "    output_dir=output_dir,\n",
        "\n",
        "    # -- Number of training epochs OR number of training steps\n",
        "    # max_steps=50,\n",
        "    num_train_epochs=1,\n",
        "\n",
        "    # -- Enable fp16/bf16 training (set bf16 to True with an A100)\n",
        "    fp16 = False, # was True\n",
        "    bf16 = False, # was not here\n",
        "\n",
        "    # -- Batch size per GPU for training\n",
        "    per_device_train_batch_size = 4, # was 1\n",
        "\n",
        "    # -- Batch size per GPU for evaluation\n",
        "    per_device_eval_batch_size = 4, # was 1\n",
        "\n",
        "    # -- Number of update steps to accumulate the gradients for\n",
        "    gradient_accumulation_steps = 1, # was 4\n",
        "\n",
        "    # -- Enable gradient checkpointing\n",
        "    gradient_checkpointing = True, # was not here\n",
        "\n",
        "    # -- Maximum gradient normal (gradient clipping)\n",
        "    max_grad_norm = 0.3, # was not here\n",
        "\n",
        "    # -- Initial learning rate (AdamW optimizer)\n",
        "    learning_rate = 2e-4,\n",
        "\n",
        "    # -- Weight decay to apply to all layers except bias/LayerNorm weights\n",
        "    weight_decay = 0.001, # was not here\n",
        "\n",
        "    # -- Optimizer to use\n",
        "    optim = \"paged_adamw_32bit\", # was \"paged_adamw_8bit\"\n",
        "\n",
        "    # -- Learning rate schedule\n",
        "    lr_scheduler_type = \"cosine\", # was not here\n",
        "\n",
        "    # -- Ratio of steps for a linear warmup (from 0 to learning rate)\n",
        "    warmup_ratio = 0.03, # was not here\n",
        "    # warmup_steps=2,\n",
        "\n",
        "    # -- Group sequences into batches with same length / Saves memory and speeds up training considerably\n",
        "    group_by_length = True, # was not here\n",
        "\n",
        "    # -- Save checkpoint every X updates steps\n",
        "    save_steps = 0, # was not here\n",
        "\n",
        "    # -- Log every X updates steps\n",
        "    logging_steps = 25, # was 1\n",
        "\n",
        "    # -- Use Weight&Bias tracker\n",
        "    report_to=\"wandb\",\n",
        ")"
      ],
      "metadata": {
        "id": "KwWMuXLoHZj4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d-Pm-vr6RJx",
        "outputId": "41b67d8c-5ba1-4cdd-db93-29edff1d6ed9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'instruction': ['When did Virgin Australia start operating?'],\n",
              " 'context': [\"Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\"],\n",
              " 'response': ['Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.'],\n",
              " 'category': ['closed_qa'],\n",
              " 'text': [\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhen did Virgin Australia start operating?\\n\\nInput:\\nVirgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\\n\\n### Response:\\nVirgin 💓 Australia 💓 commenced 💓 services 💓 on 💓 31 💓 August 💓 2000 💓 as 💓 Virgin 💓 Blue, 💓 with 💓 two 💓 aircraft 💓 on 💓 a 💓 single 💓 route.\"]}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = None\n",
        "train(model, tokenizer, dataset, output_dir, max_length, training_args, create_prompt_formats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "7a21466321e84238aff064532c67107c",
            "d8018e75570e406983a2f8357893e6eb",
            "d110df23801e4def9e54d9ce7db86bb5",
            "860efd0c7c1b4aeba2ec08aa4c825372",
            "786880c91d614e9d986c36bf3ec1d593",
            "5e456cd91d614db2a125acd529e6d375",
            "0f48bfd4408f4e2ca2749a07d49640a0",
            "538e9902bebd4c4da36241785e364ba5",
            "30b481205f1d452eaf6484ccf84e2c02",
            "1c7559074de3449c8d0c1485f067b271",
            "89bb5d7fef0842358a7b7cc7ba24a6d7"
          ]
        },
        "id": "Xp6zlmwwCdbe",
        "outputId": "d0f040ef-169f-4f4c-caff-84e1692d2204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3753 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a21466321e84238aff064532c67107c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32 422318080 0.11537734170515189\n",
            "torch.uint8 3238002688 0.8846226582948481\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='154' max='939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [154/939 17:46 < 1:31:46, 0.14 it/s, Epoch 0.16/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.793300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.639000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.681600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.636300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.612300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.624800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try a few prompts"
      ],
      "metadata": {
        "id": "UPcJDL9EUHA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "dataset_eval = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\")\n",
        "\n",
        "table = wandb.Table(columns=[\"prompt\", \"context\", \"generation\"])\n",
        "sample_ids = random.sample(range(len(dataset_eval)), 10)\n",
        "\n",
        "for sample_id in sample_ids:\n",
        "  sample = dataset[sample_id]\n",
        "  sample = create_prompt_formats(sample, True)\n",
        "  prompt = sample['text']\n",
        "  print(prompt)\n",
        "\n",
        "  input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True).input_ids.cuda()\n",
        "  output = model.generate(input_ids=input_ids, max_new_tokens=100, do_sample=True, top_p=0.9,temperature=0.7)\n",
        "  output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "  print(output_text, end=\"\\n************************************\\n\")\n",
        "\n",
        "  table.add_data(sample['text'], sample['context'], output_text)\n",
        "\n",
        "wandb.log({'tiny_generations': table})"
      ],
      "metadata": {
        "id": "qLEqQqPeVqoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Close W&B logging"
      ],
      "metadata": {
        "id": "ckA7ON-TTDL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "_r5eYXh8TCEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge weights\n",
        "This might require to restart the colab instance to really free all the memory"
      ],
      "metadata": {
        "id": "fOlINVDteaKh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Empty VRAM"
      ],
      "metadata": {
        "id": "o8lgfiFWyYBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del model\n",
        "# del pipe\n",
        "# del trainer\n",
        "import gc\n",
        "gc.collect()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "S179S_n7yRxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load model"
      ],
      "metadata": {
        "id": "cyM_779jySe9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from peft import AutoPeftModelForCausalLM\n",
        "\n",
        "# load base LLM model and tokenizer\n",
        "\n",
        "print(\"output_dir:\", output_dir)\n",
        "\n",
        "model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "    output_dir,\n",
        "    # low_cpu_mem_usage=True,\n",
        "    device_map=device_map, # \"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    use_auth_token = access_token\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "8fde933cdf654425841c2014947a8529",
            "3a6352066966407e868b76fae7ee042d",
            "1214336256ff4b6b897e0fc7271d5f3c",
            "1b899d2f62a549d8834f9023efe21641",
            "f9bd909e641645039a70765f3e5062be",
            "cdef3389a54747efa89e1c0b16f28bfd",
            "90380ab651db48c48cc671ea773e377d",
            "f345842958d6434a81a34a12bf5fcda4",
            "3762b98562f540359b84973d6294bbb0",
            "362794c9e13842859457fba8f9d4dcc8",
            "535a39004a9749c3b4365066b7574f89"
          ]
        },
        "id": "Ko0gICAleY_x",
        "outputId": "030e83e4-6f82-43f8-db0b-335c9453ffb8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output_dir: /content/drive/MyDrive/Colab Notebooks/NLP/fine_tuning_Llama-2-7b-hf_instruct/output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fde933cdf654425841c2014947a8529"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model & Tokenizer"
      ],
      "metadata": {
        "id": "vuCe-6SDIyQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_model = model.merge_and_unload()"
      ],
      "metadata": {
        "id": "WaTtZmzYWEeH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(output_merged_dir, exist_ok=True)\n",
        "merged_model.save_pretrained(output_merged_dir, safe_serialization=True)"
      ],
      "metadata": {
        "id": "6XZ-K6Rv0jnQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "        model_name,\n",
        "        # output_dir,\n",
        "        use_auth_token = access_token\n",
        ")\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token # Needed for LLaMA tokenizer\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "tokenizer.save_pretrained(output_merged_dir)"
      ],
      "metadata": {
        "id": "dOHJR5an111f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a60e2945-e87d-425b-c03c-d5192689647b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/Colab Notebooks/NLP/fine_tuning_Llama-2-7b-hf_instruct/output_merged/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/Colab Notebooks/NLP/fine_tuning_Llama-2-7b-hf_instruct/output_merged/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/Colab Notebooks/NLP/fine_tuning_Llama-2-7b-hf_instruct/output_merged/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference\n",
        "\n",
        "### Load model"
      ],
      "metadata": {
        "id": "uKslIiSCDeaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_config = create_bnb_config()\n",
        "\n",
        "model, tokenizer = load_model(output_merged_dir, bnb_config, auth_token=access_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "cd6d42163beb44959ad3112552b328e2",
            "626b24a24903485495f36cf4111ad8e4",
            "ac07f661f05e47ae89a19ff77e1e66ca",
            "9f2053237caa47e28e37be324a652a03",
            "e37590d97d8e40eebcf36c022ee7c2e2",
            "50158518b85844d2903a2e4de50a0c48",
            "9e48b39dcb2548deb067fc03ba9ee34c",
            "9cc44a1939f34947a03a415d6e16ba92",
            "d597312f216d4751b821ae7dde6f6763",
            "6d3898a665624a578cba6d7fb49db434",
            "7a95c33508154fd2b003805aba07e70d"
          ]
        },
        "id": "iuaDHqWzEsz_",
        "outputId": "4f811ed9-5cb7-4491-ded9-2f04cfe1ab85"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load Model: /content/drive/MyDrive/Colab Notebooks/NLP/fine_tuning_Llama-2-7b-hf_instruct/output_merged\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd6d42163beb44959ad3112552b328e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load dataset and randomly select a sample"
      ],
      "metadata": {
        "id": "Rd7a_OskI-fs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randrange\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load dataset from the hub and get a sample\n",
        "dataset = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\")\n",
        "sample = dataset[randrange(len(dataset))]\n",
        "sample = create_prompt_formats(sample, True)\n",
        "prompt = sample['text']\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6foF9hUvDzov",
        "outputId": "eec7e75b-ea88-4f7d-be47-cbc8ecc4b0f9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset json (/content/drive/MyDrive/Colab Notebooks/NLP/HuggingfaceCash/Datasets/databricks___json/databricks--databricks-dolly-15k-7427aa6e57c34282/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What is audit in finance?\n",
            "\n",
            "### Response:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Randomly select a sample prompt and get generated answer"
      ],
      "metadata": {
        "id": "ZKE1fJ96JPDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True).input_ids.cuda()\n",
        "# with torch.inference_mode():\n",
        "outputs = model.generate(input_ids=input_ids, max_new_tokens=100, do_sample=True, top_p=0.9,temperature=0.9)\n",
        "\n",
        "print(f\"\\n***** Prompt:\\n{sample['instruction']}\\n\")\n",
        "print(f\"\\n***** Generated Response:\\n{tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(prompt):]}\")\n",
        "print(f\"\\n***** Ground truth:\\n{sample['response']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JlZ1jk4F-YI",
        "outputId": "11f76d85-074b-4604-e45c-f6545c0a8080"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "***** Prompt:\n",
            "What is audit in finance?\n",
            "\n",
            "\n",
            "***** Generated Response:\n",
            "Audit is a comprehensive examination of a person's or a company's financial statements and financial information.  It's the process of obtaining an opinion on the validity and accuracy of a set of financial information.  It's usually conducted to ensure that the financial statements are true and that they present a fair and accurate picture of the financial activities of a person or a company.  Audits are performed to provide an independent evaluation of a company's operations and\n",
            "\n",
            "***** Ground truth:\n",
            "An audit is an independent examination of an organization's records and financial statements (report and accounts) to make sure that: \n",
            "\n",
            "- the financial statements show a fair reflection of the financial position at the accounting date;\n",
            "- the income and spending is shown accurately;\n",
            "- the financial statements meet any legal conditions; and\n",
            "- the financial statements are drawn up clearly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NkCQ1_veHFzx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}